\section{Tools Used}
We have looked at and tested out the capabilities of several profilers and tools for determining the number of cache-misses, branch mispredictions and translation lookaside buffer misses.
Below we will explain why we did or did not use each of them.


\subsection{Counters}
We use these for reporting and analysing cache-misses, etc.
\begin{description}
\item[Perf]~\citep{perftool} is a performance analysing tools chiefly implemented in the Linux kernel, available from version 2.6.31.
It supports reading and reporting various counters from the \textit{hardware}, meaning it doesn't emulate the CPU or similar, as some other tools do.
It can profile the entire system or a specific process, but not subsections of a program.
\item[PAPI]~\citep{PAPI} (Performance Application Programming Interface) can use the perf kernel driver but pre-dates perf.
It requires the analysed program itself to setup and initialize PAPI, but therefore also supports starting and stopping the counter data collection at specific points in the program, enabling profiling of subsections of the program.
\end{description}

\subsubsection{Counters used}
We calculate the CPU clock cycles using the \texttt{PAPI\_TOT\_CYC} papi event which return the total number of unhalted CPU clock cycles, including when the CPU clock changes to a higher frequency in what Intel calls "Turbo Boost" or more generally "dynamic overclocking".
We believe this value to be more accurate than calculating cycles using \texttt{PAPI\_get\_real\_cyc()} which estimates the cycles based on wall time \citep{PAPI-get-real-cyc}. 

This means that \texttt{PAPI\_get\_real\_cyc()} depends on the Time Stamp Counter frequency which is constant. 
Because of this The TSC frequency is not based on CPU frequency in any way and because work gets done at CPU frequency and not TSC frequency, \texttt{PAPI\_TOT\_CYC} seems like the best choice. 
This is also recommended by Intel \citep{IntelMeasuringTheAverageUnhaltedFrequency}.

In Figure~\ref{papievents} we have listed the various counters and values we have read using PAPI and their description. Not every test uses every one of these.

Because PAPI does not support gathering all combinations of hardware at the same time, we had to gather Translation lookaside buffer misses, level 2 cache misses, and level 3 cache misses in a separate run of the program with the same parameters.
We do not believe this will have any significant influence on the results of our experiments.

\begin{figure}
\caption{PAPI counters and data sources and their description}
\label{papievents}
\center
\begin{tabular}{|l|l|}
\hline
\textbf{PAPI Source}	& \textbf{Description} \\ \hline
\texttt{PAPI\_get\_real\_cyc()}	& Real Cycles / Wall Time Cycles \\ \hline
\texttt{PAPI\_get\_real\_usec()}	& Wall Time \\ \hline
Event \texttt{PAPI\_TOT\_CYC}	& Total Cycles \\ \hline
Event \texttt{PAPI\_L1\_TCM}		& Level 1 total cache misses \\ \hline
Event \texttt{PAPI\_L2\_TCM}		& Level 2 total cache misses \\ \hline
Event \texttt{PAPI\_L3\_TCM}		& Level 3 total cache misses \\ \hline
Event \texttt{PAPI\_BR\_MSP}		& Conditional branch instructions mispredicted \\ \hline
Event \texttt{PAPI\_BR\_CN}		& Conditional branch instructions in total \\ \hline
Event \texttt{PAPI\_TLB\_DM}		& Data translation lookaside buffer misses \\ \hline
\texttt{PAPI\_get\_dmem\_info()}	& Memory information as \texttt{meminfo} object \\ \hline
\texttt{meminfo.size}			& Size of Memory used \\ \hline
\texttt{meminfo.resident}		& Size of Resident memory used \\ \hline
\texttt{meminfo.high\_water\_mark}	& Size of Peak memory usage \\ \hline



\end{tabular}
\end{figure}

\subsection{Profiler}
We use these for finding hotspots in our code; which parts our program is spending most of its time in and therefore which parts we should try to optimize.

\begin{description}
\item[Zoom]~\citep{zoomprofiler} is a profiler that supports profiling any running program without modifcation, showing a callgraph with time spent in each call among other things.
It uses the perf kernel driver. It was fairly easy to use, but seemed somewhat limited in its capabilities.
Having to start Zoom profiling before running the program, stopping Zoom when program was done and then finding the program in a long list instead of wrapping the program in the Zoom profiler somehow was also a hassle.
\item[Callgrind]~\citep{callgrind} is a callgraph analyser tool in the Valgrind suite.
It supports wrapping a program, so no manual intervention is needed.
Valgrind compiles the analysed program into an intermediate representation and runs that completely in a virtual machine to extract information for its tools.
This causes the program to run much slower while being analysed, but this is a minor concern for us.
Callgrind outputs a .callgrind file which can then be viewed in the kCacheGrind GUI program.
\end{description}