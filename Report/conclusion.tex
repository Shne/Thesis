\section{Conclusion}
In this Thesis we have described the wavelet tree, a versatile data structure offering solutions for many problem domains such as string processing, computational geometry, and data compression.
We describe in more detail how a wavelet tree is constructed and how it is queried in three ways: access, rank, and select.

We have performed a short survey on the applications of wavelet trees including efficient data compression and fast information retrieval with more detail on how the wavelet tree is used for some of the applications.

We have described some characteristics of modern CPUs that result in penalties in running time for some cases, such as cache misses (CM), branch mispredictions (BM) and translation lookaside buffer (TLB) misses.
We have described both how and why these incur penalties.

We have implemented and tested the construction of a wavelet tree, comparing it to the theoretical running and found the theoretical running time only holds up to a certain alphabet size whereafter an exponentially rising amount of TLB misses incur high penalties.
We have implemented and tested the rank and select queries and performed a number of attempts at optimizing their running times by changing how they are calculated, changing the shape of the tree, changing what is stored and how it is stored.

The optimizations are their results can be summed up as follows:

\begin{description*}
\item[Using \texttt{popcount} CPU instruction] to improve binary rank and select query running times within each node of the tree. High improvement in running time.
\item[Skewing the tree] with a controlled memory layout to reduce branch mispredictions. Worse running time.
\item[Precompute and store binary rank values] in blocks for each bitmap in each node. Use the precomputed values for the most part. High improvement in running time.
\item[Concatenate bitmaps and precomputed values] to reduce memory usage and possibly improve cache performance. Little improvement in memory usage, worse running time.
\item[Align bitmaps with memory pages] to reduce TLB misses. Slightly worse running time.
\item[Store cumulative sum of precomputed values] instead of raw binary rank values. Improvement in running time.
\item[Replace branching code with clever arithmetic] in select queries to reduce branch mispredictions. Worse running time.
\end{description*}
