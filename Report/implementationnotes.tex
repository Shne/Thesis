\section{Notes on Implementation}

\subsection{Machines used}
[Specs of all machines used for testing]

Machine 1: Jan's ASUS
Machine 2: Roland's ASUS

\subsection{Using Integers as Characters}
\label{sec:UsingIntAsChar}
The Wavelet Tree is a data structure for strings. Using the C++ \texttt{char array} or C++11 \texttt{string} types would seem natural in this case, but they each have problems.
The C and C++ \texttt{char} type is only of size 1 byte allowing us only to use an alphabet size of up to 256, making testing the running times dependency on alphabet size near-impossible as inaccuracies in the running time would likely exceed the difference in running time between the available sizes of the alphabet.

The C++11 \texttt{string} and arrays of type \texttt{char32\_t} doesn't have this problem and supports character types up to 32-bit unsigned. The problem lies in output and readability as characters corresponding to byte values below 32 are special non-printable control characters such as carriage-return and backspace. At higher byte values other non-printable control characters and otherwise unreadable characters appear again, meaning we would have to be very selective with the allowed byte values in our alphabets if we want it to be readable for output and debugging, and likely end up with an alphabet that is non-continuous on the set of byte values as a result.
Because of this, we have for convenience chosen to simply use arrays of integers as our strings in our implementations.
This will have no impact on performance as both characters and integers are simply different representations of byte values, so.

We assume in our implementation that the alphabet is always continuous on the set of byte values and store the alphabet as a minimum and maximum value, instead of storing each value in some data structure to pass around or point into.
This is for convenience as any other non-continuous alphabet could simply be mapped to a continuous run of byte values and used in the same way. 
This mapping could e.g. be done by storing an array of the alphabet in sorted order and using pointers into this array to signify the characters. 
Lookup into the array wouldn't be necessary unless printing for human reading as comparison of the pointer addresses will return same result as comparing the bytes.

We will still use the terms "character" and "string" in our descriptions of the algorithms even though we have implemented them as integers and integer arrays, as we feel "character" and "string" are more intuitive and give clarity.


\subsection{Reading Input}
At first we simply read from stdin using the \texttt{getline(cin, \&string)} function. Once we applied a profiler we found this to be horrendously slow, our Na√Øve algorithm spending about 20\% of its running time on resizing IO buffers. We then switched to using the \texttt{ifstream} class and IO time was reduced significantly to below 1\% of total running time.

\subsection{Reducing Construction Time Memory Usage}
Since the Wavelet tree is a recursively defined data structure, we also implement it recursively. Since it is also binary (or $d$-ary) we recursive into several sub-node constructors in the construction of a node, which means our compiler can't do tail-recursion optimisation (TODO: check that this is true!). This further causes any stack-allocated variables to be held in memory until we leave the scope of the constructor function.
We traverse and split the input string into its left and right parts in each node constructor and thus end up holding the input string twice in memory: once in the variable holding the input string, once in the two variables holding the left and right split strings.
This is wasted memory because we don't actually need the input string any longer once we have split it into its left and right parts.
Because we simply call one subnode constructor, then the other, once the first has completed, and finally return once both subnodes has completed constructing themselves, we end up completing the construction of the nodes in post-order.
This means we will keep the scopes of the root node, and those near the root, alive for most of the running time of the construction algorithm, and much memory is wasted.
The solution is to allocate these strings on the heap instead, passing pointers to the subnode constructors and having them delete them (as their input strings) once they have split them.
Doing this reduced the memory usage so much that we could run it for input strings with a length above $10^8$ without exhausting the about 6GB available memory on machine 1.

\subsection{Binary Rank}
A cornerstone of the rank algorithm for a Wavelet Tree is calculating the binary rank of a character on a bitmap at a node. The running time of the rank algorithm depends on the running time of the binary rank since binary rank is called once per layer of the tree in order to answer a single rank query on the tree.
To make binary rank fast, we looked at using intrinsic CPU instructions, and we found the \texttt{popcountl} instruction that counts the number of 1s in a given \texttt{unsigned long}.
We simply sum up the result of calling \texttt{popcount} on each machine word up to $index$.
When the index of the rank query is not a multiple of the machine word size, we need to constrain what part of the machine word is counted using \texttt{popcount}.
We do this by constructing a bitmask by bitshifting the number 1 $index$ times and then subtracting one, as that will create a machine word where the $index$ least significant bits are set to 1 and the rest to 0.
We then bitwise \texttt{AND} this bitmask and the machine word containing the bit corresponding to $index$, and call \texttt{popcountl} on the result.
As also noted in~\citep{Navjda13}, we don't need to count the number of 0s, although required by the algorithm, as we can simply take the number of bits in the string and subtract the number of 1s to calculate the number of 0s.


\subsection{Bitmap implementation choice}
There are several bitmap implementations available to us. In the STL there is \texttt{std::bitset<size\_t N>} and \texttt{std::vector<bool>}. From the Boost library there is \texttt{boost::dynamic\_bitset<>}.
\begin{description}
\item[\texttt{std::bitset}] While it would technically be possible to use the \texttt{std::bitset}, it requires that the size of the bitset is known at compile time and passed as a template parameter. This means we would need to recompile the program for each $n$, or size of the input string. We would also need to allocate a bitmap with room for $n$ bits for each subnode as that is the theoretically possible size required, making the size required for the bitmaps of the tree $O(n \times |nodes|) = O(n2^{log(\sigma)})$ instead of $O(n \times height) = O(n~log(\sigma))$.
[TODO: later we do preallocation and fill it up along the way. try bitset there]
We also feel that an actual practically usable implementation should be able to handle different size input at runtime instead of compiletime. 

\item[\texttt{vector<bool>}] is a specialised implementation for \texttt{bool} that packs the data so that each \texttt{bool} only takes up one bit and is not an actual C++ container, though it tries to mimic some of the behaviour. It is basically the STL implementation of a dynamically allocated bitset.

\item[\texttt{boost::dynamic\_bitset}] is the Boost library's take on a dynamic bitset. It doesn't try to mimic a container and lacks some features such as an iterator because of that. It also does not guarantee that the bits will be allocated consecutively in memory and has no raw pointer access to the data in memory. This is a problem when we want to call popcount on all machine words from beginning up to some index.
\end{description}

\subsection{Skewing the tree}
[how our skew calculations work]
